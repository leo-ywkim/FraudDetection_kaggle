{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "#!pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "import calendar\n",
    "\n",
    "# 100 개 열 보이기\n",
    "pd.set_option('display.max_row', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import  RFECV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existing Column transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform for distance\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "log_transform = [ '결제장소와주소정보1사이의거리', '결제장소와주소정보2사이의거리']\n",
    "\n",
    "for col in log_transform:\n",
    "    X_train[col] = X_train[col].apply(lambda x: np.log1p(x))\n",
    "    X_test[col] = X_test[col].apply(lambda x: np.log1p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_info consistency\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "# T:+1, F:-2, Nan:0 Encoding\n",
    "p_info_ag_cols = []\n",
    "for col in X_train.columns:\n",
    "    if '개인정보일치여부' in col:\n",
    "        p_info_ag_cols.append(col)\n",
    "    else:\n",
    "        pass\n",
    "p_info_ag_cols.remove('개인정보일치여부_4')\n",
    "\n",
    "\n",
    "for col in p_info_ag_cols:\n",
    "    X_train[col].fillna(-1, inplace=True)\n",
    "    X_test[col].fillna(-1, inplace=True)\n",
    "\n",
    "for col in p_info_ag_cols:\n",
    "    X_train[col] = X_train[col].apply(lambda x: 1 if x == 'T' else (-3 if x == 'F' else -1))\n",
    "    X_test[col] = X_test[col].apply(lambda x: 1 if x == 'T' else (-3 if x == 'F' else -1))\n",
    "\n",
    "X_train['agree_score'] = X_train[p_info_ag_cols].sum(axis=1)\n",
    "X_test['agree_score'] = X_test[p_info_ag_cols].sum(axis=1)\n",
    "\n",
    "for col in p_info_ag_cols:\n",
    "    X_train[col] = X_train[col].astype('category')\n",
    "    X_test[col] = X_test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NA ratio over th -> 0,1,2 Encoding\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "# 0.3: 55cols, 0.4: 55cols / 0.45: 54 / 0.47: 51 cols / 0.48: 48 cols\n",
    "intg_X = pd.concat([X_train.iloc[:,1:], X_test.iloc[:,1:]], axis=0)\n",
    "\n",
    "over_na = []\n",
    "\n",
    "for col in intg_X.columns:\n",
    "    na_ratio = intg_X[col].isnull().sum() / len(intg_X[col])\n",
    "    if na_ratio > 0.48:\n",
    "        over_na.append(col)\n",
    "\n",
    "for col in over_na:\n",
    "    if intg_X[col].dtype != 'object':\n",
    "        # na: 0, small: 1, big: 2 for categorical data\n",
    "        train_mean = intg_X[col].mean()\n",
    "        test_mean = intg_X[col].mean()\n",
    "        X_train[col] = X_train[col].apply(lambda x: 0 if (pd.isnull(x)) else (1 if x < train_mean else 2))\n",
    "        X_test[col] = X_test[col].apply(lambda x: 0 if (pd.isnull(x)) else (1 if x < test_mean else 2))\n",
    "    else:\n",
    "        # na: 0, else: 1\n",
    "        X_train[col] = X_train[col].apply(lambda x: 0 if (pd.isnull(x)) else 1)\n",
    "        X_test[col] = X_test[col].apply(lambda x: 0 if (pd.isnull(x)) else 1)\n",
    "\n",
    "len(over_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New column Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date, day AND drop original date column\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "def transform_day(dt):\n",
    "    days = ['mon', 'tue', 'wed', 'thur', 'fri', \"sat\", 'sun']\n",
    "    date = str(dt).split(\" \")[0]\n",
    "    yyyy = int(date.split('-')[0])\n",
    "    mm = int(date.split('-')[1])\n",
    "    dd = int(date.split('-')[2])\n",
    "    day = days[calendar.weekday(yyyy, mm, dd)]\n",
    "    return day\n",
    "\n",
    "def transform_hour(dt):\n",
    "    time = str(dt).split(' ')[1]\n",
    "    hour = int(time.split(':')[0])\n",
    "    return hour\n",
    "\n",
    "def transform_month(dt):\n",
    "    date = str(dt).split(\" \")[0]\n",
    "    mm = int(date.split('-')[1])\n",
    "    return mm\n",
    "    \n",
    "X_train[\"day\"] = X_train[\"날짜\"].apply(transform_day)\n",
    "X_test['day'] = X_test['날짜'].apply(transform_day)\n",
    "\n",
    "X_train[\"month\"] = X_train[\"날짜\"].apply(transform_month)\n",
    "X_test['month'] = X_test['날짜'].apply(transform_month)\n",
    "\n",
    "X_train[\"hour\"] = X_train[\"날짜\"].apply(transform_hour)\n",
    "X_test['hour'] = X_test['날짜'].apply(transform_hour)\n",
    "\n",
    "X_train = X_train.drop(['날짜'], axis = 1)\n",
    "X_test = X_test.drop(['날짜'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.get_dummies(X_train, columns=['day'], drop_first= True)\n",
    "X_test = pd.get_dummies(X_test, columns=['day'], drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payment information NA count\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "pay_info_count_cols = []\n",
    "for col in X_train.columns:\n",
    "    if '결제정보' in col:\n",
    "        pay_info_count_cols.append(col)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "X_train['결제정보_na_count'] = X_train[pay_info_count_cols].isnull().sum(1)\n",
    "X_test['결제정보_na_count'] = X_test[pay_info_count_cols].isnull().sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event gap day\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "event_gap_cols = []\n",
    "for col in X_train.columns:\n",
    "    if '직전결제일간격혹은이벤트' in col:\n",
    "        event_gap_cols.append(col)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for col in event_gap_cols:\n",
    "    X_train[col].fillna(0, inplace=True)\n",
    "    X_test[col].fillna(0, inplace=True)\n",
    "\n",
    "X_train['avg_event_gap'] = X_train[event_gap_cols].mean(axis=1) \n",
    "X_test['avg_event_gap'] = X_test[event_gap_cols].mean(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change T/F\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "X_train[\"잔돈\"] = X_train[\"결제금액\"].apply(lambda x : x - x//100*100)\n",
    "X_train[\"잔돈여부\"] = X_train[\"결제금액\"].apply(lambda x : x == x//100*100)\n",
    "X_test[\"잔돈\"] = X_test[\"결제금액\"].apply(lambda x : x - x//100*100)\n",
    "X_test[\"잔돈여부\"] = X_test[\"결제금액\"].apply(lambda x : x == x//100*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Weight\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "cols = ['주소정보1','주소정보2','카드정보_1','카드정보_2',\"카드정보_3\",\"카드정보_4\",\n",
    "        '카드소유주주소',\"카드사용자주소\", \"결제정보_7\", \"결제정보_20\",\n",
    "        \"개인정보갯수_1\", \"개인정보갯수_2\"]\n",
    "        \n",
    "# '결제정보_7', '결제정보_20': kdeplot 에서 fraud에 따라 차이가 많이나서 추가함\n",
    "for col in cols :\n",
    "    sum_df = pd.concat([X_train[col],X_test[col]])\n",
    "    count = sum_df.value_counts(dropna = True, normalize = True).to_dict()\n",
    "    count[-1] = -1\n",
    "    \n",
    "    new_col = col+\"의분포\"\n",
    "    \n",
    "    X_train[new_col] = X_train[col].map(count)\n",
    "    X_test[new_col] = X_test[col].map(count)\n",
    "    \n",
    "    # print(f\"{new_col} 생성완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA value\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "X_train = X_train.fillna(-1)\n",
    "X_test = X_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "for col in (X_train.columns):\n",
    "    if X_train[col].dtype == 'object':\n",
    "        enc = LabelEncoder()\n",
    "        enc.fit(list(X_train[col].values) + list(X_test[col].values))\n",
    "        X_train[col] = enc.transform(list(X_train[col].values))\n",
    "        X_test[col] = enc.transform(list(X_test[col].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import KFold as kf\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAYESAIN OPT\n",
    "def lgbm_eval(feature_fraction,bagging_fraction, output = 'score'):\n",
    "    trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "    params = {\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\":0.05,\n",
    "        'objective': 'binary',\n",
    "        \"metric\": 'auc',\n",
    "        \"verbosity\": -1,\n",
    "        'random_state': 102,\n",
    "        # 'device':\"gpu\",\n",
    "        'max_depth':12,\n",
    "        'feature_fraction':feature_fraction,\n",
    "        'bagging_fraction':bagging_fraction\n",
    "        }\n",
    "\n",
    "    lgbm_model = lgb.train(params, trn_data,\n",
    "                                num_boost_round=15000,\n",
    "                                valid_sets=[trn_data, val_data],\n",
    "                                early_stopping_rounds=300,\n",
    "                                verbose_eval=1000, \n",
    "                                # num_boost_round=18000\n",
    "                                )\n",
    "\n",
    "    # clf = lgb.train(params, trn_data, num_boost_round=1000,valid_sets =[trn_data, val_data],verbose_eval=1000,early_stopping_rounds=50)\n",
    "\n",
    "    best_iter = lgbm_model.best_iteration\n",
    "    print(best_iter)\n",
    "    lgbm_model = lgb.LGBMClassifier(**params, num_boost_round=best_iter)\n",
    "    lgbm_model.fit(X_train, y_train)\n",
    "    pred = lgbm_model.predict_proba(X_val)[:, 1]\n",
    "    roc_score = roc_auc_score(y_val, pred)\n",
    "    return roc_score\n",
    "\n",
    "# 주어진 범위 사이에서 적절한 값을 찾는다.\n",
    "pbounds = {'feature_fraction': (0.70, 0.9),\n",
    "           'bagging_fraction': (0.6, 0.9),\n",
    "          }\n",
    "\n",
    "lgbmBO = BayesianOptimization(f = lgbm_eval, pbounds = pbounds, verbose = 2, random_state = 1)\n",
    "# 메소드를 이용해 최대화!\n",
    "lgbmBO.maximize(init_points=10, n_iter = 10, acq='ei', xi=0.01)\n",
    "\n",
    "lgbmBO.max # 찾은 파라미터 값 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "          'learning_rate': 0.009,  # original: 0.005\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          'objective': 'binary',\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'random_state': 1040,\n",
    "          'feature_fraction': 0.7297,\n",
    "          'bagging_fraction': 0.7704\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[1500]\ttraining's auc: 0.95868\tvalid_1's auc: 0.94551\n",
      "[3000]\ttraining's auc: 0.974994\tvalid_1's auc: 0.955663\n",
      "[4500]\ttraining's auc: 0.984117\tvalid_1's auc: 0.961655\n",
      "[6000]\ttraining's auc: 0.989197\tvalid_1's auc: 0.964979\n",
      "[7500]\ttraining's auc: 0.992607\tvalid_1's auc: 0.967419\n",
      "[9000]\ttraining's auc: 0.994884\tvalid_1's auc: 0.969178\n",
      "[10500]\ttraining's auc: 0.99639\tvalid_1's auc: 0.970408\n",
      "[12000]\ttraining's auc: 0.997693\tvalid_1's auc: 0.971491\n",
      "[13500]\ttraining's auc: 0.998402\tvalid_1's auc: 0.971918\n",
      "[15000]\ttraining's auc: 0.998935\tvalid_1's auc: 0.972514\n",
      "[16500]\ttraining's auc: 0.99924\tvalid_1's auc: 0.972771\n",
      "Early stopping, best iteration is:\n",
      "[17182]\ttraining's auc: 0.999354\tvalid_1's auc: 0.972825\n"
     ]
    }
   ],
   "source": [
    "trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val)\n",
    "clf = lgb.train(params, trn_data, 18000, valid_sets = [trn_data, val_data], verbose_eval=1500, early_stopping_rounds=500) # 10000, 1000 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iter = clf.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.7704, feature_fraction=0.7297,\n",
       "               learning_rate=0.009, metric='auc', num_boost_round=17182,\n",
       "               objective='binary', random_state=1040, verbosity=-1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(**params, num_boost_round=best_iter)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "# sub['Fraud'] = clf.predict_proba(X_test.iloc[:,1:])[:, 1]\n",
    "sub['Fraud'] = clf.predict_proba(X_test.iloc[:,1:])[:, 1]\n",
    "sub.to_csv('result_1210_02.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50ed6b91f48180dabc09f5cf9754ecba48a5f8a882394753257ecdcc4e2cc172"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
